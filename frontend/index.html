<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Harmony AI</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

    <style>
        body {
            transition: background-color 0.3s, color 0.3s;
        }
        .dark-mode {
            background-color: #1a202c;
            color: #f7fafc;
        }
        .dark-mode input, .dark-mode output {
            color: #1a202c;
        }
        .light-mode {
            background-color: #c9d9fe;
            color: #1a202c;
        }
        .card {
            transition: transform 0.5s ease, opacity 0.5s ease;
        }
        .hidden-card {
            opacity: 0;
            transform: scale(0.9);
            pointer-events: none;
            position: absolute;
        }
        .visible-card {
            opacity: 1;
            transform: scale(1);
            pointer-events: auto;
            position: relative;
        }
        #playlistSection {
            display: none;
            margin-top: 2rem;
            width: 100%;
            max-width: 2xl;
        }
        #audioPlayer {/* Hide until audio is loaded */
            width: 100%;
            max-width: 100%;
            margin-top: 1.5rem;
        }
    </style>
</head>
<body class="dark-mode">
    <div id="app" class="flex flex-col items-center justify-center min-h-screen p-6">
        <button id="themeToggle" class="absolute top-4 right-4 px-4 py-2 bg-blue-500 text-white rounded-lg shadow-md">Switch to Light Mode</button>

        <h1 class="text-5xl font-bold text-transparent bg-gradient-to-r from-pink-500 to-red-500 bg-clip-text mb-6">Harmony AI</h1>

        <div id="cardContainer" class="relative w-full max-w-2xl">
            <!-- Card 1 -->
            <div class="card visible-card bg-gray-800 text-white shadow-lg rounded-xl p-6">
                <h2 class="text-xl font-bold mb-4">Let's detect your current mood!</h2>
                
                <!-- Webcam video -->
                <video id="video" width="100%" height="auto" autoplay muted class="rounded-lg mb-4"></video>
                
                <!-- Hidden input to store emotion -->
                <input type="hidden" id="currentMood" />
            
                <!-- Capture button -->
                <div class="flex justify-between items-center">
                    <button id="captureBtn" class="px-4 py-2 bg-yellow-500 text-white rounded-lg shadow-md">Capture Image</button>
                    <span id="emotionResult" class="text-lg font-semibold"></span>
                    <button class="nextBtn px-4 py-2 bg-blue-500 text-white rounded-lg shadow-md">Next</button>
                </div>
            </div>

            <!-- Card 3 -->
            <div class="card hidden-card bg-gray-800 text-white shadow-lg rounded-xl p-6">
                <h2 class="text-xl font-bold mb-4">Preferred Instrument (optional)</h2>
                <input type="text" id="instrument" class="w-full px-3 py-2 border rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500" placeholder="E.g., Piano">
                <div class="flex justify-between mt-4">
                    <button class="backBtn px-4 py-2 bg-gray-500 text-white rounded-lg shadow-md">Back</button>
                    <button class="nextBtn px-4 py-2 bg-blue-500 text-white rounded-lg shadow-md">Next</button>
                </div>
            </div>

            <!-- Card 4 -->
            <div class="card hidden-card bg-gray-800 text-white shadow-lg rounded-xl p-6">
                <h2 class="text-xl font-bold mb-4">Duration (in seconds)</h2>
                <input type="number" id="duration" class="w-full px-3 py-2 border rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500" placeholder="E.g., 60">
                <div class="flex justify-between mt-4">
                    <button class="backBtn px-4 py-2 bg-gray-500 text-white rounded-lg shadow-md">Back</button>
                    <button id="generateButton" class="px-4 py-2 bg-green-500 text-white rounded-lg shadow-md">Generate Music</button>
                </div>
            </div>
        </div>

        <!-- Audio player section -->
        <div id="audioSection" class="w-full max-w-2xl mt-6">
            <audio id="audioPlayer" controls class="w-full" preload="auto"></audio>
            <div id="status" class="mt-4 text-lg font-semibold text-center"></div>
        </div>
        
        <!-- Playlist Section - Hidden initially -->
        <div id="playlistSection" class="bg-gray-800 text-white shadow-lg rounded-xl p-6 w-full max-w-2xl mt-6">
            <h2 class="text-xl font-bold mb-4">Generate Playlist</h2>
            <form id="playlistForm" class="mb-4">
                <div class="mb-4">
                    <label for="playlistDuration" class="block mb-2">Duration (10-120 min)</label>
                    <input type="number" id="playlistDuration" class="w-full px-3 py-2 border rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500" placeholder="Duration (10-120 min)" min="10" max="120" value="30" />
                </div>
                <button type="submit" class="px-4 py-2 bg-green-500 text-white rounded-lg shadow-md w-full">Generate Playlist</button>
            </form>
            
            <div id="results" class="mt-4"></div>
        </div>
    </div>

    <script>
        // Global variables for audio functionality
        let audioBlob = null;
        let audioURL = null;
        
        const themeToggle = document.getElementById('themeToggle');
        const body = document.body;
        let isDarkMode = true;
        
        themeToggle.addEventListener('click', () => {
            isDarkMode = !isDarkMode;
            body.classList.toggle('dark-mode', isDarkMode);
            body.classList.toggle('light-mode', !isDarkMode);
            themeToggle.textContent = isDarkMode ? 'Switch to Light Mode' : 'Switch to Dark Mode';
    
            // Update all card colors
            document.querySelectorAll('.card, #playlistSection').forEach(element => {
                element.classList.toggle('bg-gray-800', isDarkMode);
                element.classList.toggle('bg-white', !isDarkMode);
                element.classList.toggle('text-white', isDarkMode);
                element.classList.toggle('text-black', !isDarkMode);
            });
        });
    
        const cards = document.querySelectorAll('.card');
        const generateButton = document.getElementById('generateButton');
        const audioPlayer = document.getElementById('audioPlayer');
        const status = document.getElementById('status');
        const playlistSection = document.getElementById('playlistSection');
        let currentCardIndex = 0;
        
        // Function to navigate between cards
        function navigateToCard(index) {
            if (index < 0 || index >= cards.length) return;
    
            // Hide current card
            cards[currentCardIndex].classList.add('hidden-card');
            cards[currentCardIndex].classList.remove('visible-card');
    
            // Show new card
            currentCardIndex = index;
            cards[currentCardIndex].classList.remove('hidden-card');
            cards[currentCardIndex].classList.add('visible-card');
            
            // Show playlist section only on the last card (with generate button)
            playlistSection.style.display = (index === cards.length - 1) ? 'block' : 'none';
        }
    
        // Add navigation button functionality
        cards.forEach((card, index) => {
            const nextBtn = card.querySelector('.nextBtn');
            const backBtn = card.querySelector('.backBtn');
    
            if (nextBtn) {
                nextBtn.addEventListener('click', () => {
                    navigateToCard(index + 1);

                    // Focus the first input inside the next card, if it exists
                    const nextCard = cards[index + 1];
                    if (nextCard) {
                        const input = nextCard.querySelector('input, textarea, select');
                        if (input) input.focus();
                    }
                });
            }

            if (backBtn) {
                backBtn.addEventListener('click', () => navigateToCard(index - 1));
            }
        });
    
        // Initialize first card
        cards.forEach(card => card.classList.add('hidden-card'));
        cards[0].classList.add('visible-card');
        cards[0].classList.remove('hidden-card');
    
        // Handle music generation
        // Replace the existing generateButton click event handler with this:

generateButton.addEventListener('click', async () => {
    const currentMood = document.getElementById('currentMood').value;
    const instrument = document.getElementById('instrument').value;
    // const genre = document.getElementById('genre').value;
    const duration = document.getElementById('duration').value;

    if (!currentMood || !duration) {
        status.textContent = 'Please fill in all required fields (current mood and duration).';
        return;
    }

    status.textContent = 'Generating prompt with Gemini AI...';
    
    // Call Gemini API to generate a MusicGen prompt
    try {
        const geminiResponse = await fetch('/generate-gemini-prompt', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ 
                currentMood, 
                instrument: instrument || 'any', 
                // genre: genre || 'any', 
                duration 
            })
        });
        
        if (!geminiResponse.ok) {
            throw new Error('Failed to generate prompt with Gemini AI');
        }
        
        const geminiData = await geminiResponse.json();
        const musicgenPrompt = geminiData.prompt;
        
        status.textContent = 'Generating music with MusicGen...';
        
        // Fetch the Colab ngrok URL
        const ngrokResponse = await fetch('/get_colab_ngrok_url');
        const ngrokData = await ngrokResponse.json();
        const colabNgrokUrl = ngrokData.colabNgrokUrl;
        
        // Send prompt to MusicGen
        const musicgenResponse = await fetch(`${colabNgrokUrl}/generate`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ 
                description: musicgenPrompt, 
                time: parseInt(duration) 
            })
        });
        
        if (!musicgenResponse.ok) {
            throw new Error('Failed to generate music');
        }
        
        // Fetch the generated audio file
        const audioResponse = await fetch('/audio.wav');
        const blob = await audioResponse.blob();
        const audioURL = URL.createObjectURL(blob);
        audioPlayer.src = audioURL;
        audioPlayer.play();
        status.textContent = 'Playing your generated music!';
        
    } catch (error) {
        console.error('Error:', error);
        status.textContent = `Failed: ${error.message}`;
    }
});

        // Playlist form submission
        const playlistForm = document.getElementById('playlistForm');
        const results = document.getElementById('results');
        
        playlistForm.addEventListener("submit", async (e) => {
            e.preventDefault();
            
            results.innerHTML = '<div class="text-lg font-semibold">Loading playlist...</div>';
            
            const payload = {
                mood: document.getElementById('currentMood').value || 'happy',
                genre: "therapy",
                instrument: document.getElementById('instrument').value || 'piano',
                duration: document.getElementById('playlistDuration').value || 30
            };
            
            console.log("Sending payload:", payload);
            
            try {
                // For testing - show what we're sending
                results.innerHTML = `<div class="bg-blue-900 p-4 rounded-lg mb-4">
                    <p class="font-semibold">Attempting to generate playlist with:</p>
                    <p>Mood: ${payload.mood}</p>
                    <p>Instrument: ${payload.instrument}</p>
                    <p>Duration: ${payload.duration} minutes</p>
                </div>
                <div class="text-lg font-semibold">Connecting to server...</div>`;
                
               
                // Uncomment this section when your backend is ready

                const res = await fetch("http://localhost:3002/generate_playlist", {
                    method: "POST",
                    headers: {
                        "Content-Type": "application/json"
                    },
                    body: JSON.stringify(payload)
                });
                
                const data = await res.json();
                displayPlaylistResults(data);
            
                
            } catch (err) {
                results.innerHTML = `<div class="bg-red-800 text-white p-4 rounded-lg">
                    ❌ Error connecting to the server: ${err.message}
                </div>`;
                console.error(err);
            }
        });
        
        // Function to display playlist results
        function displayPlaylistResults(data) {
    if (!data.success) {
        results.innerHTML = `<div class="bg-red-800 text-white p-4 rounded-lg">
            Failed to generate playlist.
        </div>`;
        return;
    }

    let html = `<div class="bg-green-800 text-white p-4 rounded-lg mb-4">
        <p class="text-lg font-semibold">🕒 Total Playlist Duration: ${data.total_duration}</p>
    </div>`;

    data.tracks.forEach(track => {
        html += `
            <div class="track bg-gray-700 rounded-lg p-4 mb-3">
                <h3 class="text-lg font-medium mb-2">${track.name} - ${track.artist_name}</h3>
                <audio controls class="w-full" preload="auto">
                    <source src="${track.audio}" type="audio/mpeg" />
                    Your browser does not support the audio element.
                </audio>
            </div>
        `;
    });

    results.innerHTML = html;
}

        // Face detection setup
        window.addEventListener('DOMContentLoaded', async () => {
            try {
                await Promise.all([
                    faceapi.nets.tinyFaceDetector.loadFromUri('models'),
                    faceapi.nets.faceExpressionNet.loadFromUri('models')
                ]).catch(err => {
                    console.warn("Face API models couldn't be loaded. Using fallback mode.");
                    document.getElementById('emotionResult').textContent = "API not available";
                });
                
                startVideo();
            } catch (err) {
                console.error("Error loading face-api models:", err);
                // Fallback for testing
                document.getElementById('currentMood').value = 'happy';
            }
        });

        function startVideo() {
            const video = document.getElementById('video');
            navigator.mediaDevices.getUserMedia({ video: true })
                .then(stream => video.srcObject = stream)
                .catch(err => {
                    console.error('Webcam access error:', err);
                    // Fallback
                    document.getElementById('emotionResult').textContent = "Camera not available";
                    document.getElementById('currentMood').value = 'happy';
                });
        }

        document.getElementById('captureBtn').addEventListener('click', async () => {
            const video = document.getElementById('video');
            try {
                const canvas = faceapi.createCanvasFromMedia(video);
                const displaySize = { width: video.videoWidth, height: video.videoHeight };
                faceapi.matchDimensions(canvas, displaySize);

                const detections = await faceapi.detectSingleFace(
                    video, 
                    new faceapi.TinyFaceDetectorOptions()
                ).withFaceExpressions();

                if (detections && detections.expressions) {
                    const expressions = detections.expressions;
                    const maxExpression = Object.keys(expressions).reduce(
                        (a, b) => expressions[a] > expressions[b] ? a : b
                    );
                    document.getElementById('emotionResult').textContent = `Detected: ${maxExpression}`;
                    document.getElementById('currentMood').value = maxExpression;
                } else {
                    document.getElementById('emotionResult').textContent = "No face detected";
                    // Fallback mood for testing
                    document.getElementById('currentMood').value = 'neutral';
                }
            } catch (error) {
                console.error("Face detection error:", error);
                document.getElementById('emotionResult').textContent = "Detection failed";
                // Fallback mood for testing
                document.getElementById('currentMood').value = 'neutral';
            }
        });
    </script>
</body>
</html>